{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the package\n",
    "!pip install parrotai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrotai import ParrotAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the ParrotAPI\n",
    "parrot = ParrotAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please visit https://joinparrot.ai to register your account\n",
    "\n",
    "username = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to the API. The credentials are stored in the object. You to login first before you can access the other endpoints\n",
    "login_resp = parrot.login(username=username, password=password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create task and get result LLMs task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP Request\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*POST /ai/text_completion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include your ACCESS TOKEN in HTTP Authorization header \n",
    "\n",
    "*Authorization: Bearer Token*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Key | Type | Value |\n",
    "|---------|---------|---------|\n",
    "| messages | List | This is a list that contains the messages intended for the video generation. Each message within the list is represented as a small JSON object specifying the role (such as \"user\") and the actual content of the message (e.g., \"Hello!\"). This setup helps the AI understand the context and the kind of interaction that's taking place. |\n",
    "| configs | JSON | This parameter is a JSON object encompassing a variety of settings you can adjust to customize the video generation process. It includes several sub-parameters, which we will describe next, allowing you to control different aspects of the generation. |\n",
    "| model |  String | Specifies the AI model used for generating the LLMs. Default value is \"gemma-7b\". |\n",
    "| temperature | Float | The temperature setting controls the randomness or diversity of the generation process. A higher temperature value encourages the model to explore a wider range of possibilities, making the output more varied and sometimes more creative. |\n",
    "| top_k |  Integer | This integer value determines the sampling strategy by limiting the selection to the k most likely next tokens at each step of the generation. A lower value of k results in the model focusing more on the higher probability tokens, often leading to more predictable and coherent outcomes. |\n",
    "| top_p |  Float | Similar to top_k, top_p controls the breadth of token selection based on cumulative probability. Setting a lower top_p value means the model will sample from a smaller, more likely set of tokens, which can help in maintaining the relevance and quality of the content generated. |\n",
    "| max_tokens |  Integer | This parameter sets the maximum number of tokens the model can generate. It acts as a cap, ensuring that the generation process does not exceed a certain length, which is crucial for keeping the content focused and within desired constraints. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Craft Your Input: Gather your messages including who's speaking and what's said, e.g., {\"role\": \"user\", \"content\": \"What's the weather like?\"}. Keep messages clear and relevant.\n",
    "\n",
    "2. Choose a Model: Pick an AI model, like \"gemma-7b\". The model influences and style of replies.\n",
    "\n",
    "3. Set Your Parameters: Adjust settings for:\n",
    "- temperature: Affects creativity. Higher for more varied responses.\n",
    "- top_k and top_p: Controls response diversity. Lower numbers for more focused answers.\n",
    "- max_tokens: Sets the maximum length of replies. Keep it practical for chatbot interactions.\n",
    "\n",
    "4. Fine-tune for Quality: Experiment with temperature, top_k, and top_p to find the sweet spot between creativity and relevance.\n",
    "\n",
    "5. Limit Response Length: Use max_tokens to ensure responses are concise and to the point.\n",
    "\n",
    "6. Evaluate and Adjust: Review the generated responses. If they don't meet your needs, tweak the input or settings.\n",
    "\n",
    "7. Iterate for Perfection: Continuously refine your approach based on outcomes to enhance the chatbot's effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parrot API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = parrot.text_generation(messages, model, temperature, top_k, top_p, max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returns the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'is_success': True,\n",
       "  'data': {'task_id': '7a3a6b229a584e8fb8cd1876d1258da9',\n",
       "   'total_tasks': 1,\n",
       "   'percent': 100,\n",
       "   'status': 'COMPLETED',\n",
       "   'response': 'Hello, and thank you for visiting my conversation today. I hope you have a good day as well. Is there anything I can help you with today?'},\n",
       "  'configs': {'model': 'gemma-7b',\n",
       "   'temperature': 0.7,\n",
       "   'top_k': 50,\n",
       "   'top_p': 0.9,\n",
       "   'max_new_tokens': 512,\n",
       "   'task_name': 'tasks.parrot_llm_gemma_7b_task',\n",
       "   'task_type': 'LLM-GEMMA-7B',\n",
       "   'queue_name': 'llm_gemma_7b_queue',\n",
       "   'messages': [{'role': 'user', 'content': 'Hello, have a good day!'}]}},\n",
       " 'errors': [],\n",
       " 'error_description': '',\n",
       " 'start_time': '2024-03-06 21:22:08.141725',\n",
       " 'end_time': '2024-03-06 21:22:12.287595',\n",
       " 'host_of_client_call_request': '103.186.100.36',\n",
       " 'total_time_by_second': 4.145875,\n",
       " 'status': 'success'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hello, have a good day!\"}\n",
    "]\n",
    "resp = parrot.text_generation(\n",
    "    messages=messages,\n",
    "    max_tokens=512,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    top_k=50,\n",
    ")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, and thank you for visiting my conversation today. I hope you have a good day as well. Is there anything I can help you with today?\n"
     ]
    }
   ],
   "source": [
    "if resp[\"data\"][\"is_success\"]:\n",
    "    content = resp[\"data\"][\"data\"][\"response\"]\n",
    "    print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
